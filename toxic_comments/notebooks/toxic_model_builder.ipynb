{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fd1f8-2eb4-4c6e-ac19-8f867f5270de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://www.kaggle.com/sathianpong/multi-label-classification-baseline/notebook?select=train_preprocessed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adeb23fd-41ac-4655-802e-123c04a06a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/jason/toxic_model/train_preprocessed.csv\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f696115-1092-46ba-acf4-5ad48ce76505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on im...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  identity_hate  insult  \\\n",
       "0  explanation why the edits made under my userna...            0.0     0.0   \n",
       "1  d aww  he matches this background colour i m s...            0.0     0.0   \n",
       "2  hey man  i m really not trying to edit war  it...            0.0     0.0   \n",
       "3    more i can t make any real suggestions on im...            0.0     0.0   \n",
       "4  you  sir  are my hero  any chance you remember...            0.0     0.0   \n",
       "\n",
       "   obscene  severe_toxic  threat  toxic  \n",
       "0      0.0           0.0     0.0    0.0  \n",
       "1      0.0           0.0     0.0    0.0  \n",
       "2      0.0           0.0     0.0    0.0  \n",
       "3      0.0           0.0     0.0    0.0  \n",
       "4      0.0           0.0     0.0    0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(train_path)\n",
    "df = df.drop([\"id\", \"set\", \"toxicity\"], axis=1)\n",
    "\n",
    "df.shape\n",
    "df.head()\n",
    "df = df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41384668-7700-40be-b135-10b77ff7659d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(df.columns)\n",
    "labels.remove(\"comment_text\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3376aa18-b4ec-4965-8b09-36fdffeb1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.update(\n",
    "    [\n",
    "        \"zero\",\n",
    "        \"one\",\n",
    "        \"two\",\n",
    "        \"three\",\n",
    "        \"four\",\n",
    "        \"five\",\n",
    "        \"six\",\n",
    "        \"seven\",\n",
    "        \"eight\",\n",
    "        \"nine\",\n",
    "        \"ten\",\n",
    "        \"may\",\n",
    "        \"also\",\n",
    "        \"across\",\n",
    "        \"among\",\n",
    "        \"beside\",\n",
    "        \"however\",\n",
    "        \"yet\",\n",
    "        \"within\",\n",
    "    ]\n",
    ")\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "\n",
    "\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "\n",
    "df[\"comment_text\"] = df[\"comment_text\"].apply(removeStopWords)\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "\n",
    "df[\"comment_text\"] = df[\"comment_text\"].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da554204-f90d-4585-808c-e507b398dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "MAX_VOCAB = 500\n",
    "\n",
    "encoder = layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=MAX_VOCAB, standardize=\"lower_and_strip_punctuation\"\n",
    ")\n",
    "sequences = df[\"comment_text\"].values\n",
    "targets = df[labels].values\n",
    "encoder.adapt(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab6b44e3-41f1-4b00-9663-7051ca51b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        encoder,\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=len(encoder.get_vocabulary()), output_dim=64, mask_zero=True\n",
    "        ),\n",
    "        tf.keras.layers.LSTM(64),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(targets.shape[1], activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10603592-d64c-45ae-97db-d2307a56c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    metrics=[tf.keras.metrics.CategoricalCrossentropy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7a97e55-8fd6-4e56-b71a-4d7c4bc7cef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(450, 6)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sequences, targets, test_size=0.1, random_state=42\n",
    ")\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a059fad-10e0-4d4f-8e0f-7181d3803ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 12s 331ms/step - loss: 0.6911 - categorical_crossentropy: 0.4264 - val_loss: 0.6880 - val_categorical_crossentropy: 0.2871\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 3s 185ms/step - loss: 0.6853 - categorical_crossentropy: 0.4263 - val_loss: 0.6817 - val_categorical_crossentropy: 0.2871\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 3s 233ms/step - loss: 0.6781 - categorical_crossentropy: 0.4263 - val_loss: 0.6730 - val_categorical_crossentropy: 0.2870\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 3s 203ms/step - loss: 0.6677 - categorical_crossentropy: 0.4263 - val_loss: 0.6597 - val_categorical_crossentropy: 0.2870\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.6502 - categorical_crossentropy: 0.4261 - val_loss: 0.6355 - val_categorical_crossentropy: 0.2873\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.6144 - categorical_crossentropy: 0.4261 - val_loss: 0.5759 - val_categorical_crossentropy: 0.2903\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 3s 215ms/step - loss: 0.5137 - categorical_crossentropy: 0.4310 - val_loss: 0.4382 - val_categorical_crossentropy: 0.3080\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 3s 186ms/step - loss: 0.3860 - categorical_crossentropy: 0.4369 - val_loss: 0.3382 - val_categorical_crossentropy: 0.3101\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 3s 186ms/step - loss: 0.3103 - categorical_crossentropy: 0.4353 - val_loss: 0.2785 - val_categorical_crossentropy: 0.3068\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 3s 210ms/step - loss: 0.2689 - categorical_crossentropy: 0.4328 - val_loss: 0.2441 - val_categorical_crossentropy: 0.3031\n"
     ]
    }
   ],
   "source": [
    "_ = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b2a89ba-9a68-4a88-bac3-afc21844caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fc907da-da4d-4000-97d3-8485bba02fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======identity_hate\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n",
      "=======insult\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97        47\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.94        50\n",
      "   macro avg       0.47      0.50      0.48        50\n",
      "weighted avg       0.88      0.94      0.91        50\n",
      "\n",
      "=======obscene\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98        48\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.96        50\n",
      "   macro avg       0.48      0.50      0.49        50\n",
      "weighted avg       0.92      0.96      0.94        50\n",
      "\n",
      "=======severe_toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n",
      "=======threat\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n",
      "=======toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97        47\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.94        50\n",
      "   macro avg       0.47      0.50      0.48        50\n",
      "weighted avg       0.88      0.94      0.91        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "THRESH = 0.5\n",
    "for i in range(len(labels)):\n",
    "    y_true = y_test[:, i]\n",
    "    y_pred = (pred[:, i] > THRESH).astype(int)\n",
    "    print(f\"======={labels[i]}\")\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
